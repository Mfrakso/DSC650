This project involves processing a CSV file containing mobile user data using Apache Spark and Hive. The steps include loading the data into Hive tables, performing transformations, and applying machine learning models, followed by storing the results into HBase. The pipeline utilizes multiple components of the Hadoop ecosystem and Spark's capabilities for data processing and machine learning.

Prerequisites
Apache Spark
Apache Hive
Apache HBase
Hadoop Distributed File System (HDFS)
PySpark
HappyBase (for interacting with HBase)
Docker (optional, for setting up local environments)
